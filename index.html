<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="UTF-8" />
		<meta
			name="viewport"
			content="width=device-width, initial-scale=1.0"
		/>
		<title>Real-time Speech-to-Text Transcription</title>
		<style>
			* {
				margin: 0;
				padding: 0;
				box-sizing: border-box;
			}

			body {
				font-family: "Segoe UI", system-ui, sans-serif;
				background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
				min-height: 100vh;
				padding: 20px;
			}

			.container {
				max-width: 1400px;
				margin: 0 auto;
				background: white;
				border-radius: 15px;
				box-shadow: 0 10px 40px rgba(0, 0, 0, 0.3);
				overflow: hidden;
			}

			.header {
				background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
				color: white;
				padding: 30px;
				text-align: center;
			}

			.header h1 {
				font-size: 2.5rem;
				margin-bottom: 10px;
			}

			.header p {
				font-size: 1.1rem;
				opacity: 0.95;
			}

			.status-bar {
				background: rgba(255, 255, 255, 0.1);
				padding: 15px 30px;
				display: flex;
				justify-content: space-between;
				align-items: center;
				flex-wrap: wrap;
				gap: 15px;
			}

			.status-item {
				display: flex;
				align-items: center;
				gap: 8px;
				font-size: 0.95rem;
			}

			.status-indicator {
				width: 10px;
				height: 10px;
				border-radius: 50%;
				background: #ff4444;
				animation: pulse 2s ease-in-out infinite;
			}

			.status-indicator.connected {
				background: #44ff44;
			}

			@keyframes pulse {
				0%,
				100% {
					opacity: 1;
				}
				50% {
					opacity: 0.5;
				}
			}

			.content {
				padding: 30px;
			}

			.controls-grid {
				display: grid;
				grid-template-columns: repeat(auto-fit, minmax(350px, 1fr));
				gap: 20px;
				margin-bottom: 30px;
			}

			.control-card {
				background: #f8f9fa;
				border: 2px solid #e9ecef;
				border-radius: 12px;
				padding: 20px;
			}

			.control-card h3 {
				color: #495057;
				margin-bottom: 15px;
				font-size: 1.1rem;
				display: flex;
				align-items: center;
				gap: 8px;
			}

			.provider-buttons {
				display: grid;
				grid-template-columns: 1fr 1fr;
				gap: 10px;
				margin-bottom: 15px;
			}

			.provider-btn {
				padding: 12px;
				border: 2px solid #dee2e6;
				background: white;
				border-radius: 8px;
				cursor: pointer;
				font-weight: 500;
				transition: all 0.3s;
			}

			.provider-btn:hover {
				border-color: #667eea;
				background: #f8f9fa;
			}

			.provider-btn.active {
				background: #667eea;
				color: white;
				border-color: #667eea;
			}

			.config-group {
				margin-top: 15px;
			}

			.config-group label {
				display: block;
				font-weight: 500;
				margin-bottom: 5px;
				color: #495057;
				font-size: 0.9rem;
			}

			.config-group select {
				width: 100%;
				padding: 8px;
				border: 1px solid #ced4da;
				border-radius: 6px;
				background: white;
				font-size: 0.95rem;
			}

			.record-button {
				width: 100%;
				padding: 16px;
				font-size: 1.1rem;
				font-weight: 600;
				border: none;
				border-radius: 8px;
				cursor: pointer;
				transition: all 0.3s;
				margin-bottom: 15px;
			}

			.record-button.start {
				background: #28a745;
				color: white;
			}

			.record-button.start:hover {
				background: #218838;
				transform: translateY(-2px);
				box-shadow: 0 4px 12px rgba(40, 167, 69, 0.3);
			}

			.record-button.stop {
				background: #dc3545;
				color: white;
				animation: pulse-red 1.5s ease-in-out infinite;
			}

			@keyframes pulse-red {
				0%,
				100% {
					box-shadow: 0 0 0 0 rgba(220, 53, 69, 0.7);
				}
				50% {
					box-shadow: 0 0 0 10px rgba(220, 53, 69, 0);
				}
			}

			@keyframes slideIn {
				from {
					transform: translateX(400px);
					opacity: 0;
				}
				to {
					transform: translateX(0);
					opacity: 1;
				}
			}

			@keyframes slideOut {
				from {
					transform: translateX(0);
					opacity: 1;
				}
				to {
					transform: translateX(400px);
					opacity: 0;
				}
			}

			.record-button:disabled {
				background: #6c757d;
				cursor: not-allowed;
				opacity: 0.6;
			}

			.audio-visualizer {
				height: 80px;
				background: linear-gradient(to bottom, #e9ecef, #f8f9fa);
				border: 2px solid #dee2e6;
				border-radius: 8px;
				position: relative;
				overflow: hidden;
				margin-top: 15px;
			}

			.visualizer-bar {
				position: absolute;
				bottom: 0;
				width: 4px;
				background: linear-gradient(to top, #667eea, #764ba2);
				transition: height 0.1s ease;
				border-radius: 2px 2px 0 0;
			}

			.metrics-grid {
				display: grid;
				grid-template-columns: repeat(auto-fit, minmax(120px, 1fr));
				gap: 12px;
			}

			.metric-card {
				background: white;
				border: 2px solid #e9ecef;
				border-radius: 8px;
				padding: 15px;
				text-align: center;
				transition: transform 0.2s;
			}

			.metric-card:hover {
				transform: translateY(-2px);
				border-color: #667eea;
			}

			.metric-value {
				font-size: 1.8rem;
				font-weight: 700;
				color: #667eea;
				display: block;
				margin-bottom: 5px;
			}

			.metric-label {
				font-size: 0.85rem;
				color: #6c757d;
				text-transform: uppercase;
				letter-spacing: 0.5px;
			}

			.transcription-section {
				margin-top: 30px;
			}

			.transcription-header {
				display: flex;
				justify-content: space-between;
				align-items: center;
				margin-bottom: 15px;
			}

			.transcription-header h3 {
				color: #495057;
				font-size: 1.2rem;
			}

			.clear-btn {
				padding: 8px 16px;
				background: #6c757d;
				color: white;
				border: none;
				border-radius: 6px;
				cursor: pointer;
				font-size: 0.9rem;
			}

			.clear-btn:hover {
				background: #5a6268;
			}

			.transcription-box {
				background: #f8f9fa;
				border: 2px solid #dee2e6;
				border-radius: 12px;
				padding: 20px;
				min-height: 300px;
				max-height: 500px;
				overflow-y: auto;
				font-family: "Segoe UI", system-ui, sans-serif;
			}

			.transcript-item {
				background: white;
				border-left: 4px solid #667eea;
				border-radius: 8px;
				padding: 15px;
				margin-bottom: 12px;
				box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
				animation: slideIn 0.3s ease-out;
			}

			@keyframes slideIn {
				from {
					opacity: 0;
					transform: translateX(-20px);
				}
				to {
					opacity: 1;
					transform: translateX(0);
				}
			}

			.transcript-item.interim {
				background: #fff3cd;
				border-left-color: #ffc107;
				font-style: italic;
				opacity: 0.8;
			}

			.transcript-meta {
				display: flex;
				justify-content: space-between;
				align-items: center;
				margin-bottom: 8px;
				font-size: 0.85rem;
				color: #6c757d;
			}

			.transcript-time {
				font-weight: 500;
			}

			.transcript-badges {
				display: flex;
				gap: 8px;
			}

			.badge {
				padding: 3px 8px;
				border-radius: 4px;
				font-size: 0.75rem;
				font-weight: 600;
			}

			.badge-confidence {
				background: #d4edda;
				color: #155724;
			}

			.badge-confidence.medium {
				background: #fff3cd;
				color: #856404;
			}

			.badge-confidence.low {
				background: #f8d7da;
				color: #721c24;
			}

			.badge-latency {
				background: #e2e3e5;
				color: #495057;
			}

			.badge-provider {
				background: #667eea;
				color: white;
			}

			.badge-speaker {
				background: #17a2b8;
				color: white;
			}

			.transcript-text {
				font-size: 1.05rem;
				line-height: 1.6;
				color: #212529;
			}

			.speaker-label {
				font-weight: 600;
				color: #17a2b8;
				margin-right: 8px;
			}

			.debug-log {
				margin-top: 30px;
				background: #212529;
				color: #00ff00;
				border-radius: 12px;
				padding: 20px;
				font-family: "Courier New", monospace;
				font-size: 0.85rem;
				max-height: 300px;
				overflow-y: auto;
			}

			.debug-log h4 {
				color: #00ff00;
				margin-bottom: 10px;
			}

			.log-entry {
				margin: 4px 0;
				padding: 2px 0;
				border-bottom: 1px solid #333;
			}

			.log-entry.error {
				color: #ff4444;
			}

			.log-entry.success {
				color: #44ff44;
			}

			.log-entry.info {
				color: #44aaff;
			}

			.placeholder {
				text-align: center;
				padding: 60px 20px;
				color: #6c757d;
				font-style: italic;
			}

			.error-message {
				background: #f8d7da;
				color: #721c24;
				border: 1px solid #f5c6cb;
				border-radius: 8px;
				padding: 15px;
				margin-top: 15px;
			}

			.file-upload-area {
				border: 2px dashed #dee2e6;
				border-radius: 8px;
				padding: 20px;
				text-align: center;
				cursor: pointer;
				transition: all 0.3s;
				background: white;
				margin-bottom: 15px;
			}

			.file-upload-area:hover {
				border-color: #667eea;
				background: #f8f9fa;
			}

			.file-upload-area.dragover {
				border-color: #667eea;
				background: #e7f3ff;
			}

			.file-upload-icon {
				font-size: 2rem;
				margin-bottom: 10px;
			}

			.file-input {
				display: none;
			}

			.file-info {
				margin-top: 10px;
				padding: 10px;
				background: #e7f3ff;
				border-radius: 6px;
				font-size: 0.9rem;
			}

			.audio-controls {
				display: flex;
				gap: 10px;
				align-items: center;
				margin-top: 10px;
			}

			.audio-controls audio {
				flex: 1;
				height: 40px;
			}

			.play-btn {
				padding: 10px 20px;
				background: #667eea;
				color: white;
				border: none;
				border-radius: 6px;
				cursor: pointer;
				font-weight: 600;
				transition: all 0.3s;
			}

			.play-btn:hover {
				background: #5568d3;
			}

			.play-btn:disabled {
				background: #6c757d;
				cursor: not-allowed;
				opacity: 0.6;
			}
		</style>
	</head>
	<body>
		<div class="container">
			<div class="header">
				<h1>üé§ Real-time Speech-to-Text</h1>
				<p>Live transcription with Deepgram and AWS Transcribe</p>

				<div class="status-bar">
					<div class="status-item">
						<div
							class="status-indicator"
							id="wsIndicator"
						></div>
						<span id="wsStatus">Connecting...</span>
					</div>
					<div class="status-item">
						<span id="providerStatus">No provider selected</span>
					</div>
					<div class="status-item">
						<span id="recordingStatus">Ready</span>
					</div>
				</div>
			</div>

			<div class="content">
				<div class="controls-grid">
					<!-- Provider Selection -->
					<div class="control-card">
						<h3>üîß Provider Selection</h3>
						<div class="provider-buttons">
							<button
								class="provider-btn active"
								data-provider="deepgram"
							>
								Deepgram
							</button>
							<button
								class="provider-btn"
								data-provider="aws"
							>
								AWS Transcribe
							</button>
						</div>

						<div class="config-group">
							<label for="modelSelect">Model:</label>
							<select id="modelSelect">
								<option
									value="nova-3"
									selected
								>
									Nova-3 (Latest)
								</option>
								<option value="nova-2">Nova-2</option>
								<option value="nova">Nova</option>
								<option value="enhanced">Enhanced</option>
								<option value="base">Base</option>
							</select>
						</div>

						<div class="config-group">
							<label for="languageSelect">Language:</label>
							<select id="languageSelect">
								<option value="en-US">English (US)</option>
								<option value="en-GB">English (UK)</option>
								<option value="es">Spanish</option>
								<option value="fr">French</option>
								<option value="de">German</option>
							</select>
						</div>

						<div class="config-group">
							<label
								style="
									display: flex;
									align-items: center;
									cursor: pointer;
									margin-top: 10px;
								"
							>
								<input
									type="checkbox"
									id="diarizationToggle"
									checked
									style="
										margin-right: 8px;
										width: 18px;
										height: 18px;
										cursor: pointer;
									"
								/>
								<span>Enable Speaker Diarization</span>
							</label>
						</div>

						<div
							class="config-group"
							style="margin-top: 15px"
						>
							<label
								for="playbackSpeed"
								style="
									display: block;
									margin-bottom: 8px;
									font-weight: 500;
								"
							>
								File Transcription Speed:
								<span id="speedValue">1.0x</span>
							</label>
							<input
								type="range"
								id="playbackSpeed"
								min="0.5"
								max="4"
								step="0.5"
								value="1"
								style="width: 100%; cursor: pointer"
							/>
							<div
								style="
									display: flex;
									justify-content: space-between;
									font-size: 0.75rem;
									color: #6c757d;
									margin-top: 4px;
								"
							>
								<span>0.5x (Slower)</span>
								<span>4x (Faster)</span>
							</div>
						</div>
					</div>

					<!-- Recording Controls -->
					<div class="control-card">
						<h3>üéôÔ∏è Recording</h3>
						<button
							class="record-button start"
							id="recordBtn"
						>
							Start Recording
						</button>

						<div
							class="audio-visualizer"
							id="visualizer"
						></div>
					</div>

					<!-- Audio File Upload -->
					<div class="control-card">
						<h3>üìÅ Upload Audio File</h3>
						<p
							style="
								font-size: 0.9rem;
								color: #6c757d;
								margin-bottom: 10px;
							"
						>
							üí° Use the speed slider above to transcribe faster
							(2x-4x recommended)
						</p>
						<div
							class="file-upload-area"
							id="fileUploadArea"
						>
							<div class="file-upload-icon">üìé</div>
							<div>Click or drag audio file here</div>
							<div
								style="
									font-size: 0.85rem;
									color: #6c757d;
									margin-top: 5px;
								"
							>
								Supports MP3, WAV, M4A, FLAC
							</div>
						</div>
						<input
							type="file"
							id="audioFileInput"
							class="file-input"
							accept="audio/*"
						/>
						<div
							id="fileInfo"
							class="file-info"
							style="display: none"
						></div>
						<div
							class="audio-controls"
							id="audioControls"
							style="display: none"
						>
							<audio
								id="audioPlayer"
								controls
							></audio>
							<button
								class="play-btn"
								id="transcribeFileBtn"
							>
								Transcribe
							</button>
							<button
								class="play-btn"
								id="compareProvidersBtn"
								style="
									background: linear-gradient(
										135deg,
										#f093fb 0%,
										#f5576c 100%
									);
								"
							>
								üî¨ Compare AWS vs Deepgram
							</button>
						</div>
					</div>

					<!-- Metrics -->
					<div class="control-card">
						<h3>üìä Metrics</h3>
						<div class="metrics-grid">
							<div class="metric-card">
								<span
									class="metric-value"
									id="durationMetric"
									>0:00</span
								>
								<span class="metric-label">Duration</span>
							</div>
							<div class="metric-card">
								<span
									class="metric-value"
									id="wordsMetric"
									>0</span
								>
								<span class="metric-label">Words</span>
							</div>
							<div class="metric-card">
								<span
									class="metric-value"
									id="wpmMetric"
									>0</span
								>
								<span class="metric-label">WPM</span>
							</div>
							<div class="metric-card">
								<span
									class="metric-value"
									id="confidenceMetric"
									>--</span
								>
								<span class="metric-label">Confidence</span>
							</div>
							<div class="metric-card">
								<span
									class="metric-value"
									id="latencyMetric"
									>--</span
								>
								<span class="metric-label">Latency (ms)</span>
							</div>
							<div class="metric-card">
								<span
									class="metric-value"
									id="accuracyMetric"
									>--</span
								>
								<span class="metric-label">Accuracy</span>
							</div>
						</div>
					</div>
				</div>

				<!-- Transcription Display -->
				<div class="transcription-section">
					<div class="transcription-header">
						<h3>üìù Live Transcription</h3>
						<div style="display: flex; gap: 10px">
							<button
								class="clear-btn"
								id="downloadBtn"
							>
								Download
							</button>
							<button
								class="clear-btn"
								id="clearBtn"
							>
								Clear
							</button>
						</div>
					</div>
					<div
						class="transcription-box"
						id="transcriptionBox"
					>
						<div class="placeholder">
							Click "Start Recording" and speak into your
							microphone to see transcription...
						</div>
					</div>
				</div>

				<!-- Debug Log -->
				<div
					class="debug-log"
					id="debugLog"
				>
					<h4>üêõ Debug Log</h4>
					<div id="logEntries"></div>
				</div>
			</div>
		</div>

		<script>
			class RealtimeTranscription {
				constructor() {
					this.ws = null
					this.isRecording = false
					this.currentProvider = "deepgram"
					this.mediaRecorder = null
					this.audioStream = null
					this.audioContext = null
					this.analyser = null
					this.visualizerBars = []

					this.initElements()
					this.initEventListeners()
					this.initVisualizer()
					this.connectWebSocket()
				}

				initElements() {
					this.wsIndicator = document.getElementById("wsIndicator")
					this.wsStatus = document.getElementById("wsStatus")
					this.providerStatus =
						document.getElementById("providerStatus")
					this.recordingStatus =
						document.getElementById("recordingStatus")
					this.recordBtn = document.getElementById("recordBtn")
					this.clearBtn = document.getElementById("clearBtn")
					this.downloadBtn = document.getElementById("downloadBtn")
					this.transcriptionBox =
						document.getElementById("transcriptionBox")
					this.modelSelect = document.getElementById("modelSelect")
					this.languageSelect =
						document.getElementById("languageSelect")
					this.diarizationToggle =
						document.getElementById("diarizationToggle")
					this.playbackSpeedSlider =
						document.getElementById("playbackSpeed")
					this.speedValue = document.getElementById("speedValue")
					this.visualizer = document.getElementById("visualizer")
					this.logEntries = document.getElementById("logEntries")

					// File upload elements
					this.fileUploadArea =
						document.getElementById("fileUploadArea")
					this.audioFileInput =
						document.getElementById("audioFileInput")
					this.fileInfo = document.getElementById("fileInfo")
					this.audioControls =
						document.getElementById("audioControls")
					this.audioPlayer = document.getElementById("audioPlayer")
					this.transcribeFileBtn =
						document.getElementById("transcribeFileBtn")
					this.selectedFile = null

					// Metric elements
					this.durationMetric =
						document.getElementById("durationMetric")
					this.wordsMetric = document.getElementById("wordsMetric")
					this.wpmMetric = document.getElementById("wpmMetric")
					this.confidenceMetric =
						document.getElementById("confidenceMetric")
					this.latencyMetric =
						document.getElementById("latencyMetric")
					this.accuracyMetric =
						document.getElementById("accuracyMetric")
				}

				initEventListeners() {
					// Provider buttons
					document
						.querySelectorAll(".provider-btn")
						.forEach((btn) => {
							btn.addEventListener("click", (e) => {
								document
									.querySelectorAll(".provider-btn")
									.forEach((b) =>
										b.classList.remove("active")
									)
								e.target.classList.add("active")
								this.currentProvider = e.target.dataset.provider
								this.updateProviderModels()
								this.log(
									`Provider switched to: ${this.currentProvider}`,
									"info"
								)
							})
						})

					// Record button
					this.recordBtn.addEventListener("click", () => {
						if (this.isRecording) {
							this.stopRecording()
						} else {
							this.startRecording()
						}
					})

					// Clear button
					this.clearBtn.addEventListener("click", () => {
						this.transcriptionBox.innerHTML =
							'<div class="placeholder">Transcription cleared. Speak to continue...</div>'
						this.log("Transcription cleared", "info")
					})

					// Download button
					this.downloadBtn.addEventListener("click", () => {
						this.downloadTranscript()
					})

					// Playback speed slider
					this.playbackSpeedSlider.addEventListener("input", (e) => {
						const speed = parseFloat(e.target.value)
						this.speedValue.textContent = `${speed}x`
						// Also update the audio player playback rate if audio is loaded
						if (this.audioPlayer.src) {
							this.audioPlayer.playbackRate = speed
						}
						this.log(`Playback speed set to ${speed}x`, "info")
					})

					// File upload area click
					this.fileUploadArea.addEventListener("click", () => {
						this.audioFileInput.click()
					})

					// File input change
					this.audioFileInput.addEventListener("change", (e) => {
						const file = e.target.files[0]
						if (file) {
							this.handleFileSelect(file)
						}
					})

					// Drag and drop
					this.fileUploadArea.addEventListener("dragover", (e) => {
						e.preventDefault()
						e.stopPropagation()
						this.fileUploadArea.classList.add("dragover")
					})

					this.fileUploadArea.addEventListener("dragleave", (e) => {
						e.preventDefault()
						e.stopPropagation()
						this.fileUploadArea.classList.remove("dragover")
					})

					this.fileUploadArea.addEventListener("drop", (e) => {
						e.preventDefault()
						e.stopPropagation()
						this.fileUploadArea.classList.remove("dragover")

						const file = e.dataTransfer.files[0]
						if (file && file.type.startsWith("audio/")) {
							this.handleFileSelect(file)
						} else {
							alert("Please drop an audio file")
						}
					})

					// Transcribe file button
					this.transcribeFileBtn.addEventListener("click", () => {
						this.transcribeAudioFile()
					})

					// Compare providers button
					document
						.getElementById("compareProvidersBtn")
						.addEventListener("click", () => {
							this.compareProviders()
						})
				}

				initVisualizer() {
					// Create visualizer bars
					for (let i = 0; i < 50; i++) {
						const bar = document.createElement("div")
						bar.className = "visualizer-bar"
						bar.style.left = `${i * 5}px`
						this.visualizer.appendChild(bar)
						this.visualizerBars.push(bar)
					}
				}

				updateProviderModels() {
					const models = {
						deepgram: [
							{ value: "nova-3", label: "Nova-3 (Latest)" },
							{ value: "nova-2", label: "Nova-2" },
							{ value: "nova", label: "Nova" },
							{ value: "enhanced", label: "Enhanced" },
							{ value: "base", label: "Base" },
						],
						aws: [
							{ value: "standard", label: "Standard" },
							{ value: "medical", label: "Medical" },
							{ value: "call-center", label: "Call Center" },
						],
					}

					this.modelSelect.innerHTML = models[this.currentProvider]
						.map(
							(m) =>
								`<option value="${m.value}">${m.label}</option>`
						)
						.join("")
				}

				connectWebSocket() {
					this.log("Connecting to WebSocket...", "info")

					const WS_URL = window.location.hostname === 'localhost' || window.location.hostname === '127.0.0.1' ? 'ws://localhost:8766' : 'wss://realtime-transcription-service.onrender.com';
                	this.ws = new WebSocket(WS_URL);

					this.ws.onopen = () => {
						this.log("‚úÖ WebSocket connected", "success")
						this.wsIndicator.classList.add("connected")
						this.wsStatus.textContent = "Connected"
					}

					this.ws.onmessage = (event) => {
						try {
							const data = JSON.parse(event.data)
							this.handleMessage(data)
						} catch (e) {
							this.log(`Error parsing message: ${e}`, "error")
						}
					}

					this.ws.onerror = (error) => {
						this.log(`‚ùå WebSocket error: ${error}`, "error")
					}

					this.ws.onclose = () => {
						this.log("‚ö†Ô∏è WebSocket disconnected", "error")
						this.wsIndicator.classList.remove("connected")
						this.wsStatus.textContent = "Disconnected"

						// Attempt reconnect
						setTimeout(() => this.connectWebSocket(), 3000)
					}
				}

				handleMessage(data) {
					this.log(`Received: ${data.type}`, "info")

					switch (data.type) {
						case "connection_established":
							this.log(
								`Connection ID: ${data.connection_id}`,
								"success"
							)
							break

						case "transcription_started":
							this.log(
								`‚úÖ Transcription started with ${data.provider}`,
								"success"
							)
							this.providerStatus.textContent = `Using ${data.provider}`
							// Now it's safe to start sending audio
							this.readyToSendAudio = true
							this.log(
								`üì° Ready to send audio to ${data.provider}`,
								"success"
							)
							break

						case "transcription_result":
							this.handleTranscription(data.data)
							break

						case "metrics_update":
							this.updateMetrics(data.data)
							break

						case "transcription_timeout":
							this.log(`‚ö†Ô∏è Timeout: ${data.message}`, "warning")
							this.showNotification(data.message, "warning")
							break

						case "transcription_reconnected":
							this.log(
								`‚úÖ Reconnected: ${data.message}`,
								"success"
							)
							this.showNotification(data.message, "success")
							break

						case "queue_warning":
							this.log(
								`‚ö†Ô∏è Processing Queue: ${data.message}`,
								"warning"
							)
							this.showNotification(
								"AWS processing slower than upload - consider reducing speed",
								"warning"
							)
							break

						case "error":
							this.log(`‚ùå Error: ${data.message}`, "error")
							alert(`Error: ${data.message}`)
							break

						case "transcription_stopped":
							this.log("Transcription stopped", "info")
							break
					}
				}

				handleTranscription(data) {
					// Log the raw data to debug
					console.log("Raw transcription data:", data)

					const speakerInfo =
						data.speaker !== undefined
							? ` (Speaker ${data.speaker})`
							: ""
					const confidence =
						data.confidence !== undefined ? data.confidence : 1.0
					const isFinal =
						data.is_final !== undefined ? data.is_final : true
					const text = data.text || data.transcript || ""

					this.log(
						`üìù Transcription: "${text}"${speakerInfo} (final=${isFinal}, confidence=${confidence.toFixed(
							2
						)})`,
						"success"
					)

					// Skip empty transcriptions
					if (!text || text.trim() === "") {
						this.log("‚ö†Ô∏è Skipping empty transcription", "info")
						return
					}

					// Skip interim results only during live recording
					// For file transcription, show all results since we're processing complete audio
					if (!isFinal && this.isRecording) {
						this.log(
							"‚ö†Ô∏è Skipping interim result during live recording",
							"info"
						)
						return
					}

					// Remove placeholder
					const placeholder =
						this.transcriptionBox.querySelector(".placeholder")
					if (placeholder) {
						placeholder.remove()
					}

					// Create transcript item (only for final results)
					const item = document.createElement("div")
					item.className = "transcript-item"
					if (!isFinal) {
						item.classList.add("interim")
					}

					const confidenceClass =
						confidence > 0.9
							? ""
							: confidence > 0.7
							? "medium"
							: "low"

					// Build speaker badge if diarization data exists
					const speakerBadge =
						data.speaker !== undefined
							? `<span class="badge badge-speaker">Speaker ${data.speaker}</span>`
							: ""

					// Build transcript text with speaker label if available
					const transcriptText =
						data.speaker !== undefined
							? `<span class="speaker-label">Speaker ${data.speaker}:</span>${text}`
							: text

					const timestamp = data.timestamp
						? new Date(data.timestamp).toLocaleTimeString()
						: new Date().toLocaleTimeString()
					const provider = data.provider || this.currentProvider
					const latency =
						data.latency !== undefined ? data.latency : "--"

					item.innerHTML = `
                    <div class="transcript-meta">
                        <span class="transcript-time">${timestamp}</span>
                        <div class="transcript-badges">
                            <span class="badge badge-provider">${provider}</span>
                            ${speakerBadge}
                            <span class="badge badge-confidence ${confidenceClass}">${Math.round(
						confidence * 100
					)}%</span>
                            <span class="badge badge-latency">${latency}ms</span>
                        </div>
                    </div>
                    <div class="transcript-text">${transcriptText}</div>
                `

					this.transcriptionBox.appendChild(item)
					this.transcriptionBox.scrollTop =
						this.transcriptionBox.scrollHeight
					this.log("‚úÖ Transcription added to display", "success")
				}

				updateMetrics(metrics) {
					const minutes = Math.floor(metrics.duration / 60)
					const seconds = Math.floor(metrics.duration % 60)
					this.durationMetric.textContent = `${minutes}:${seconds
						.toString()
						.padStart(2, "0")}`
					this.wordsMetric.textContent = metrics.word_count
					this.wpmMetric.textContent = Math.round(metrics.wpm)
					this.confidenceMetric.textContent = `${Math.round(
						metrics.avg_confidence * 100
					)}%`
					this.latencyMetric.textContent = Math.round(
						metrics.avg_latency
					)
					this.accuracyMetric.textContent = `${Math.round(
						metrics.estimated_accuracy * 100
					)}%`
				}

				async startRecording() {
					try {
						this.log("üé§ Requesting microphone access...", "info")

						this.audioStream =
							await navigator.mediaDevices.getUserMedia({
								audio: {
									channelCount: 1,
									sampleRate: 16000,
									echoCancellation: true,
									noiseSuppression: true,
								},
							})

						this.log("‚úÖ Microphone access granted", "success")

						// Setup audio visualizer and PCM processor
						this.audioContext = new (window.AudioContext ||
							window.webkitAudioContext)()
						const mediaSource =
							this.audioContext.createMediaStreamSource(
								this.audioStream
							)

						// Log the actual sample rate being used
						const actualSampleRate = this.audioContext.sampleRate
						this.log(
							`üéµ Audio context sample rate: ${actualSampleRate}Hz (target: 16000Hz)`,
							"info"
						)

						// Setup analyzer for visualization
						this.analyser = this.audioContext.createAnalyser()
						this.analyser.fftSize = 256
						mediaSource.connect(this.analyser)
						this.startVisualization()

						// Set up the audio processor but don't send audio yet
						const bufferSize = 4096
						this.scriptProcessor =
							this.audioContext.createScriptProcessor(
								bufferSize,
								1,
								1
							)
						mediaSource.connect(this.scriptProcessor)
						this.scriptProcessor.connect(
							this.audioContext.destination
						)

						// Flag to control when to start sending audio
						this.readyToSendAudio = false
						this._audioLogCount = 0

						this.scriptProcessor.onaudioprocess = (
							audioProcessingEvent
						) => {
							// Only send audio if we're ready AND websocket is open
							if (
								this.readyToSendAudio &&
								this.ws.readyState === WebSocket.OPEN
							) {
								let inputData =
									audioProcessingEvent.inputBuffer.getChannelData(
										0
									)

								// Resample if needed (browser might use 44.1kHz or 48kHz instead of 16kHz)
								if (actualSampleRate !== 16000) {
									inputData = this.resampleAudio(
										inputData,
										actualSampleRate,
										16000
									)
								}

								// Convert Float32Array to Int16Array (PCM 16-bit)
								const pcmData = new Int16Array(inputData.length)
								for (let i = 0; i < inputData.length; i++) {
									const s = Math.max(
										-1,
										Math.min(1, inputData[i])
									)
									pcmData[i] = s < 0 ? s * 0x8000 : s * 0x7fff
								}

								this.ws.send(pcmData.buffer)
								// Only log occasionally to reduce spam
								this._audioLogCount++
								if (
									this._audioLogCount <= 3 ||
									this._audioLogCount % 100 == 0
								) {
									this.log(
										`üì§ Sent audio chunk #${this._audioLogCount} (${pcmData.buffer.byteLength} bytes @ 16kHz)`,
										"info"
									)
								}
							}
						}

						// Now send start command
						const config = {
							command: "start_transcription",
							provider: this.currentProvider,
							model: this.modelSelect.value,
							language: this.languageSelect.value,
							smart_format: true,
							interim_results: true, // Enable interim results for real-time feedback
							diarize: this.diarizationToggle.checked,
						}

						this.ws.send(JSON.stringify(config))
						this.log(
							`üöÄ Starting ${this.currentProvider} transcription (diarization: ${config.diarize})...`,
							"info"
						)

						// Wait for transcription_started message (handled in handleMessage)
						// The flag will be set to true when we receive confirmation

						// Update UI
						this.isRecording = true
						this.recordBtn.textContent = "‚èπÔ∏è Stop Recording"
						this.recordBtn.className = "record-button stop"
						this.recordingStatus.textContent = "üî¥ Recording"
					} catch (error) {
						this.log(
							`‚ùå Failed to start recording: ${error.message}`,
							"error"
						)
						alert(`Failed to start recording: ${error.message}`)
					}
				}

				stopRecording() {
					this.log("üõë Stopping recording...", "info")

					// Stop sending audio immediately
					this.readyToSendAudio = false

					// Stop script processor
					if (this.scriptProcessor) {
						this.scriptProcessor.disconnect()
						this.scriptProcessor.onaudioprocess = null
						this.scriptProcessor = null
					}

					if (this.audioStream) {
						this.audioStream
							.getTracks()
							.forEach((track) => track.stop())
					}

					if (this.audioContext) {
						this.audioContext.close()
					}

					// Send stop command
					if (this.ws.readyState === WebSocket.OPEN) {
						this.ws.send(
							JSON.stringify({ command: "stop_transcription" })
						)
					}

					// Update UI
					this.isRecording = false
					this.recordBtn.textContent = "üé§ Start Recording"
					this.recordBtn.className = "record-button start"
					this.recordingStatus.textContent = "Ready"
					this.stopVisualization()

					this.log("‚úÖ Recording stopped", "success")
				}

				startVisualization() {
					const dataArray = new Uint8Array(
						this.analyser.frequencyBinCount
					)

					const animate = () => {
						if (!this.isRecording) return

						this.analyser.getByteFrequencyData(dataArray)

						const step = Math.floor(
							dataArray.length / this.visualizerBars.length
						)
						this.visualizerBars.forEach((bar, i) => {
							const value = dataArray[i * step]
							const height = (value / 255) * 100
							bar.style.height = `${height}%`
						})

						requestAnimationFrame(animate)
					}

					animate()
				}

				stopVisualization() {
					this.visualizerBars.forEach((bar) => {
						bar.style.height = "0%"
					})
				}

				handleFileSelect(file) {
					this.log(
						`üìÅ File selected: ${file.name} (${(
							file.size /
							1024 /
							1024
						).toFixed(2)} MB)`,
						"info"
					)

					// Store the file and create a blob URL for the audio player
					this.selectedFile = file
					this.selectedFileName = file.name
					this.selectedFileSize = file.size
					this.selectedFileType = file.type

					// Show file info
					this.fileInfo.style.display = "block"
					this.fileInfo.innerHTML = `
                    <strong>üìÑ ${file.name}</strong><br>
                    Size: ${(file.size / 1024 / 1024).toFixed(2)} MB | Type: ${
						file.type
					}
                `

					// Create a new blob URL for preview (this won't interfere with file reading)
					const blob = new Blob([file], { type: file.type })
					const url = URL.createObjectURL(blob)
					this.audioPlayer.src = url
					// Set playback rate to match slider
					this.audioPlayer.playbackRate = parseFloat(
						this.playbackSpeedSlider.value
					)
					this.audioControls.style.display = "flex"
				}

				async transcribeAudioFile() {
					if (!this.selectedFile) {
						alert("Please select an audio file first")
						return
					}

					if (this.isRecording) {
						alert("Please stop live recording first")
						return
					}

					this.log("üéµ Starting audio file transcription...", "info")
					this.transcribeFileBtn.disabled = true
					this.transcribeFileBtn.textContent = "Transcribing..."

					try {
						// Read the file using FileReader to avoid reference issues
						const arrayBuffer = await new Promise(
							(resolve, reject) => {
								const reader = new FileReader()
								reader.onload = (e) => resolve(e.target.result)
								reader.onerror = (e) =>
									reject(new Error("Failed to read file"))
								reader.readAsArrayBuffer(this.selectedFile)
							}
						)

						const audioContext = new (window.AudioContext ||
							window.webkitAudioContext)()
						const audioBuffer = await audioContext.decodeAudioData(
							arrayBuffer
						)

						this.log(
							`‚úÖ Audio decoded: ${audioBuffer.duration.toFixed(
								2
							)}s, ${audioBuffer.sampleRate}Hz`,
							"success"
						)

						// Check file duration for AWS
						if (isAWS && audioBuffer.duration > 120) {
							const useDeepgram = confirm(
								`‚ö†Ô∏è AWS Transcribe has memory issues with files longer than 2 minutes.\n\n` +
									`Your file is ${Math.round(
										audioBuffer.duration / 60
									)} minutes long.\n\n` +
									`Recommendation: Use Deepgram instead for better reliability.\n\n` +
									`Click OK to switch to Deepgram, or Cancel to try AWS anyway (may fail).`
							)

							if (useDeepgram) {
								this.currentProvider = "deepgram"
								this.modelSelect.value = "nova-3"
								this.updateProviderModels()
								this.log(
									"‚úÖ Switched to Deepgram for large file",
									"success"
								)
							} else {
								this.log(
									"‚ö†Ô∏è Proceeding with AWS (may encounter memory errors)",
									"warning"
								)
								this.showNotification(
									"AWS may fail on large files - consider using Deepgram",
									"warning"
								)
							}
						}

						// Get audio data (convert to mono if stereo)
						let audioData
						if (audioBuffer.numberOfChannels === 1) {
							audioData = audioBuffer.getChannelData(0)
						} else {
							// Mix down to mono
							const left = audioBuffer.getChannelData(0)
							const right = audioBuffer.getChannelData(1)
							audioData = new Float32Array(left.length)
							for (let i = 0; i < left.length; i++) {
								audioData[i] = (left[i] + right[i]) / 2
							}
						}

						// Resample to 16kHz if needed
						const targetSampleRate = 16000
						let resampledData

						if (audioBuffer.sampleRate !== targetSampleRate) {
							this.log(
								`üîÑ Resampling from ${audioBuffer.sampleRate}Hz to ${targetSampleRate}Hz...`,
								"info"
							)
							resampledData = this.resampleAudio(
								audioData,
								audioBuffer.sampleRate,
								targetSampleRate
							)
						} else {
							resampledData = audioData
						}

						// Send start command
						const config = {
							command: "start_transcription",
							provider: this.currentProvider,
							model: this.modelSelect.value,
							language: this.languageSelect.value,
							smart_format: true,
							interim_results: false,
							diarize: this.diarizationToggle.checked,
						}

						this.ws.send(JSON.stringify(config))
						this.log(
							`üöÄ Starting transcription with ${this.currentProvider}...`,
							"info"
						)

						// Wait for the transcription to be fully initialized
						await new Promise((resolve) =>
							setTimeout(resolve, 2000)
						)
						this.log(
							"‚è≥ Waiting for transcription service to initialize...",
							"info"
						)

						// Send audio in chunks
						const chunkSize = 8000 // 0.5 second of audio at 16kHz
						const numChunks = Math.ceil(
							resampledData.length / chunkSize
						)

						this.recordingStatus.textContent =
							"üéµ Transcribing file..."

						// Get playback speed for rate limiting
						const playbackSpeed = parseFloat(
							this.playbackSpeedSlider.value
						)

						// AWS-specific rate limiting to prevent memory overflow
						const maxSpeed = isAWS ? 1.0 : 4.0 // AWS limited to 1x only, Deepgram can handle 4x
						const effectiveSpeed =
							isAWS && playbackSpeed > maxSpeed
								? maxSpeed
								: playbackSpeed

						if (isAWS && playbackSpeed > maxSpeed) {
							this.log(
								`‚ö†Ô∏è AWS Transcribe limited to ${maxSpeed}x speed (you selected ${playbackSpeed}x)`,
								"warning"
							)
							this.showNotification(
								`AWS Transcribe limited to ${maxSpeed}x speed for memory stability`,
								"warning"
							)
						}

						for (let i = 0; i < numChunks; i++) {
							const start = i * chunkSize
							const end = Math.min(
								start + chunkSize,
								resampledData.length
							)
							const chunk = resampledData.slice(start, end)

							// Convert Float32Array to Int16Array (PCM 16-bit)
							const pcmData = new Int16Array(chunk.length)
							for (let j = 0; j < chunk.length; j++) {
								const s = Math.max(-1, Math.min(1, chunk[j]))
								pcmData[j] = s < 0 ? s * 0x8000 : s * 0x7fff
							}

							if (this.ws.readyState === WebSocket.OPEN) {
								this.ws.send(pcmData.buffer)

								// Log every 10 chunks to reduce spam
								if (i % 10 === 0 || i === numChunks - 1) {
									this.log(
										`üì§ Sent chunk ${
											i + 1
										}/${numChunks} (${effectiveSpeed}x speed)`,
										"info"
									)
								}
							}

							// Delay adjusted by effective speed with minimum threshold
							const baseDelay = 500 // 500ms per chunk at 1x speed
							const adjustedDelay = baseDelay / effectiveSpeed
							const minDelay = isAWS ? 600 : 100 // AWS needs longer minimum delay (600ms)
							let finalDelay = Math.max(adjustedDelay, minDelay)

							// Add extra delay every 10 chunks for AWS to allow processing catchup
							if (isAWS && i % 10 === 0 && i > 0) {
								finalDelay += 500 // Extra 500ms every 10 chunks
								this.log(
									`‚è∏Ô∏è Pausing for AWS processing (chunk ${i})`,
									"info"
								)
							}

							await new Promise((resolve) =>
								setTimeout(resolve, finalDelay)
							)
						}

						this.log(
							"‚úÖ All audio chunks sent, waiting for final results...",
							"info"
						)

						// Wait for final results to come back
						await new Promise((resolve) =>
							setTimeout(resolve, 3000)
						)

						// Send stop command
						this.ws.send(
							JSON.stringify({ command: "stop_transcription" })
						)

						this.log(
							"‚úÖ Audio file transcription complete",
							"success"
						)
						this.recordingStatus.textContent = "Ready"
					} catch (error) {
						this.log(
							`‚ùå Error transcribing file: ${error.message}`,
							"error"
						)
						alert(`Error transcribing file: ${error.message}`)
					} finally {
						this.transcribeFileBtn.disabled = false
						this.transcribeFileBtn.textContent = "Transcribe"
					}
				}

				resampleAudio(audioData, fromSampleRate, toSampleRate) {
					// Simple linear interpolation resampling
					const ratio = fromSampleRate / toSampleRate
					const newLength = Math.round(audioData.length / ratio)
					const result = new Float32Array(newLength)

					for (let i = 0; i < newLength; i++) {
						const position = i * ratio
						const index = Math.floor(position)
						const fraction = position - index

						if (index + 1 < audioData.length) {
							result[i] =
								audioData[index] * (1 - fraction) +
								audioData[index + 1] * fraction
						} else {
							result[i] = audioData[index]
						}
					}

					return result
				}

				downloadTranscript() {
					const transcriptItems =
						this.transcriptionBox.querySelectorAll(
							".transcript-item"
						)

					if (transcriptItems.length === 0) {
						alert("No transcription to download")
						return
					}

					// Create text content
					let textContent = "TRANSCRIPTION REPORT\n"
					textContent += "=".repeat(60) + "\n"
					textContent += `Date: ${new Date().toLocaleString()}\n`
					textContent += `Provider: ${this.currentProvider}\n`
					textContent += `Total Segments: ${transcriptItems.length}\n`
					textContent += "=".repeat(60) + "\n\n"

					transcriptItems.forEach((item, index) => {
						const time =
							item.querySelector(".transcript-time")
								?.textContent || ""
						const text =
							item.querySelector(".transcript-text")
								?.textContent || ""
						const badges = item.querySelectorAll(".badge")

						let metadata = ""
						badges.forEach((badge) => {
							metadata += `[${badge.textContent}] `
						})

						textContent += `[${index + 1}] ${time}\n`
						if (metadata) textContent += `${metadata}\n`
						textContent += `${text}\n\n`
					})

					// Create downloadable file
					const blob = new Blob([textContent], { type: "text/plain" })
					const url = URL.createObjectURL(blob)
					const a = document.createElement("a")
					a.href = url
					a.download = `transcript_${
						new Date()
							.toISOString()
							.replace(/:/g, "-")
							.split(".")[0]
					}.txt`
					document.body.appendChild(a)
					a.click()
					document.body.removeChild(a)
					URL.revokeObjectURL(url)

					this.log(
						`üì• Transcript downloaded (${transcriptItems.length} segments)`,
						"success"
					)

					// Also offer JSON format
					if (confirm("Download JSON format as well?")) {
						this.downloadTranscriptJSON()
					}
				}

				downloadTranscriptJSON() {
					const transcriptItems =
						this.transcriptionBox.querySelectorAll(
							".transcript-item"
						)

					if (transcriptItems.length === 0) {
						return
					}

					const jsonData = {
						metadata: {
							date: new Date().toISOString(),
							provider: this.currentProvider,
							totalSegments: transcriptItems.length,
						},
						transcripts: [],
					}

					transcriptItems.forEach((item, index) => {
						const time =
							item.querySelector(".transcript-time")
								?.textContent || ""
						const text =
							item.querySelector(".transcript-text")
								?.textContent || ""
						const providerBadge =
							item.querySelector(".badge-provider")
								?.textContent || ""
						const speakerBadge =
							item.querySelector(".badge-speaker")?.textContent ||
							""
						const confidenceBadge =
							item.querySelector(".badge-confidence")
								?.textContent || ""
						const latencyBadge =
							item.querySelector(".badge-latency")?.textContent ||
							""

						jsonData.transcripts.push({
							index: index + 1,
							timestamp: time,
							text: text,
							provider: providerBadge,
							speaker: speakerBadge,
							confidence: confidenceBadge,
							latency: latencyBadge,
							isFinal: !item.classList.contains("interim"),
						})
					})

					const blob = new Blob([JSON.stringify(jsonData, null, 2)], {
						type: "application/json",
					})
					const url = URL.createObjectURL(blob)
					const a = document.createElement("a")
					a.href = url
					a.download = `transcript_${
						new Date()
							.toISOString()
							.replace(/:/g, "-")
							.split(".")[0]
					}.json`
					document.body.appendChild(a)
					a.click()
					document.body.removeChild(a)
					URL.revokeObjectURL(url)

					this.log("üì• JSON transcript downloaded", "success")
				}

				async compareProviders() {
					if (!this.selectedFile) {
						alert("Please select an audio file first")
						return
					}

					if (this.isRecording) {
						alert("Please stop live recording first")
						return
					}

					this.log("üî¨ Starting provider comparison...", "info")
					this.showNotification(
						"Starting comparison: AWS Call Center vs Deepgram Nova-3",
						"info"
					)

					const compareBtn = document.getElementById(
						"compareProvidersBtn"
					)
					compareBtn.disabled = true
					compareBtn.textContent = "‚è≥ Comparing..."

					try {
						// Store original settings
						const originalProvider = this.currentProvider
						const originalModel = this.modelSelect.value

						// Results storage
						const results = {
							aws: {
								transcripts: [],
								startTime: null,
								endTime: null,
								speakers: new Set(),
							},
							deepgram: {
								transcripts: [],
								startTime: null,
								endTime: null,
								speakers: new Set(),
							},
						}

						// Clear transcription box
						this.transcriptionBox.innerHTML =
							'<div class="placeholder">Running comparison test...</div>'

						// Test 1: AWS Call Center with diarization
						this.log(
							"üìû Testing AWS Transcribe Call Center...",
							"info"
						)
						this.currentProvider = "aws"
						this.modelSelect.value = "call-center"
						this.diarizationToggle.checked = true

						results.aws.startTime = Date.now()
						await this.transcribeAudioFileForComparison(results.aws)
						results.aws.endTime = Date.now()

						this.log(
							`‚úÖ AWS completed in ${(
								(results.aws.endTime - results.aws.startTime) /
								1000
							).toFixed(2)}s`,
							"success"
						)

						// Wait a bit between tests
						await new Promise((resolve) =>
							setTimeout(resolve, 2000)
						)

						// Test 2: Deepgram Nova-3 with diarization
						this.log("üåü Testing Deepgram Nova-3...", "info")
						this.currentProvider = "deepgram"
						this.modelSelect.value = "nova-3"
						this.diarizationToggle.checked = true

						results.deepgram.startTime = Date.now()
						await this.transcribeAudioFileForComparison(
							results.deepgram
						)
						results.deepgram.endTime = Date.now()

						this.log(
							`‚úÖ Deepgram completed in ${(
								(results.deepgram.endTime -
									results.deepgram.startTime) /
								1000
							).toFixed(2)}s`,
							"success"
						)

						// Generate comparison report
						this.generateComparisonReport(results)

						// Restore original settings
						this.currentProvider = originalProvider
						this.modelSelect.value = originalModel
						this.updateProviderModels()

						this.showNotification(
							"Comparison complete! Check downloads.",
							"success"
						)
					} catch (error) {
						this.log(
							`‚ùå Error during comparison: ${error.message}`,
							"error"
						)
						alert(`Error during comparison: ${error.message}`)
					} finally {
						compareBtn.disabled = false
						compareBtn.textContent = "üî¨ Compare AWS vs Deepgram"
					}
				}

				async transcribeAudioFileForComparison(resultStorage) {
					// Read and process audio file
					const arrayBuffer = await new Promise((resolve, reject) => {
						const reader = new FileReader()
						reader.onload = (e) => resolve(e.target.result)
						reader.onerror = (e) =>
							reject(new Error("Failed to read file"))
						reader.readAsArrayBuffer(this.selectedFile)
					})

					const audioContext = new (window.AudioContext ||
						window.webkitAudioContext)()
					const audioBuffer = await audioContext.decodeAudioData(
						arrayBuffer
					)

					// Get mono audio data
					let audioData
					if (audioBuffer.numberOfChannels === 1) {
						audioData = audioBuffer.getChannelData(0)
					} else {
						const left = audioBuffer.getChannelData(0)
						const right = audioBuffer.getChannelData(1)
						audioData = new Float32Array(left.length)
						for (let i = 0; i < left.length; i++) {
							audioData[i] = (left[i] + right[i]) / 2
						}
					}

					// Resample to 16kHz if needed
					const targetSampleRate = 16000
					let resampledData
					if (audioBuffer.sampleRate !== targetSampleRate) {
						resampledData = this.resampleAudio(
							audioData,
							audioBuffer.sampleRate,
							targetSampleRate
						)
					} else {
						resampledData = audioData
					}

					// Setup transcription callback to capture results
					const originalCallback = this.handleTranscription.bind(this)
					this.handleTranscription = (data) => {
						// Store transcript
						if (data.text && data.text.trim()) {
							resultStorage.transcripts.push({
								text: data.text,
								confidence: data.confidence,
								is_final: data.is_final,
								speaker: data.speaker,
								timestamp: data.timestamp,
							})

							// Track unique speakers
							if (
								data.speaker !== undefined &&
								data.speaker !== null
							) {
								resultStorage.speakers.add(data.speaker)
							}
						}
						// Don't display during comparison
					}

					// Send start command
					const config = {
						command: "start_transcription",
						provider: this.currentProvider,
						model: this.modelSelect.value,
						language: "en-US",
						smart_format: true,
						interim_results: true,
						diarize: true,
					}

					this.ws.send(JSON.stringify(config))
					await new Promise((resolve) => setTimeout(resolve, 2000))

					// Send audio in chunks
					const chunkSize = 8000
					const numChunks = Math.ceil(
						resampledData.length / chunkSize
					)
					const isAWS = this.currentProvider === "aws"
					const effectiveSpeed = isAWS ? 1.5 : 2.0 // Use safe speeds

					for (let i = 0; i < numChunks; i++) {
						const start = i * chunkSize
						const end = Math.min(
							start + chunkSize,
							resampledData.length
						)
						const chunk = resampledData.slice(start, end)

						const pcmData = new Int16Array(chunk.length)
						for (let j = 0; j < chunk.length; j++) {
							const s = Math.max(-1, Math.min(1, chunk[j]))
							pcmData[j] = s < 0 ? s * 0x8000 : s * 0x7fff
						}

						if (this.ws.readyState === WebSocket.OPEN) {
							this.ws.send(pcmData.buffer)
						}

						const baseDelay = 500
						const adjustedDelay = baseDelay / effectiveSpeed
						const minDelay = isAWS ? 400 : 100
						const finalDelay = Math.max(adjustedDelay, minDelay)

						await new Promise((resolve) =>
							setTimeout(resolve, finalDelay)
						)
					}

					// Wait for final results
					await new Promise((resolve) => setTimeout(resolve, 3000))

					// Send stop command
					this.ws.send(
						JSON.stringify({ command: "stop_transcription" })
					)

					// Restore original callback
					this.handleTranscription = originalCallback
				}

				generateComparisonReport(results) {
					// Calculate metrics
					const awsDuration =
						(results.aws.endTime - results.aws.startTime) / 1000
					const deepgramDuration =
						(results.deepgram.endTime -
							results.deepgram.startTime) /
						1000

					const awsText = results.aws.transcripts
						.map((t) => t.text)
						.join(" ")
					const deepgramText = results.deepgram.transcripts
						.map((t) => t.text)
						.join(" ")

					const awsWords = awsText
						.split(/\s+/)
						.filter((w) => w.length > 0).length
					const deepgramWords = deepgramText
						.split(/\s+/)
						.filter((w) => w.length > 0).length

					const awsAvgConfidence =
						results.aws.transcripts.reduce(
							(sum, t) => sum + (t.confidence || 0),
							0
						) / results.aws.transcripts.length
					const deepgramAvgConfidence =
						results.deepgram.transcripts.reduce(
							(sum, t) => sum + (t.confidence || 0),
							0
						) / results.deepgram.transcripts.length

					const awsSpeakers = results.aws.speakers.size
					const deepgramSpeakers = results.deepgram.speakers.size

					// Calculate word error rate approximation (simple character-based similarity)
					const similarity = this.calculateSimilarity(
						awsText.toLowerCase(),
						deepgramText.toLowerCase()
					)

					// Generate report
					let report =
						"‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n"
					report +=
						"         TRANSCRIPTION PROVIDER COMPARISON REPORT\n"
					report +=
						"‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n\n"
					report += `Date: ${new Date().toLocaleString()}\n`
					report += `File: ${this.selectedFile.name}\n`
					report += `Test: AWS Transcribe Call Center vs Deepgram Nova-3\n\n`

					report +=
						"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n"
					report += "                     PERFORMANCE METRICS\n"
					report +=
						"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n\n"

					report += `‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n`
					report += `‚îÇ Metric                  ‚îÇ AWS          ‚îÇ Deepgram     ‚îÇ\n`
					report += `‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n`
					report += `‚îÇ Processing Time         ‚îÇ ${awsDuration.toFixed(
						2
					)}s        ‚îÇ ${deepgramDuration.toFixed(2)}s       ‚îÇ\n`
					report += `‚îÇ Total Words             ‚îÇ ${awsWords
						.toString()
						.padEnd(12)} ‚îÇ ${deepgramWords
						.toString()
						.padEnd(12)} ‚îÇ\n`
					report += `‚îÇ Avg Confidence          ‚îÇ ${(
						awsAvgConfidence * 100
					).toFixed(1)}%       ‚îÇ ${(
						deepgramAvgConfidence * 100
					).toFixed(1)}%      ‚îÇ\n`
					report += `‚îÇ Speakers Detected       ‚îÇ ${awsSpeakers
						.toString()
						.padEnd(12)} ‚îÇ ${deepgramSpeakers
						.toString()
						.padEnd(12)} ‚îÇ\n`
					report += `‚îÇ Transcript Segments     ‚îÇ ${results.aws.transcripts.length
						.toString()
						.padEnd(12)} ‚îÇ ${results.deepgram.transcripts.length
						.toString()
						.padEnd(12)} ‚îÇ\n`
					report += `‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\n`

					report +=
						"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n"
					report += "                    DIARIZATION ANALYSIS\n"
					report +=
						"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n\n"

					report += `AWS Speaker Distribution:\n`
					const awsSpeakerCounts = {}
					results.aws.transcripts.forEach((t) => {
						const speaker =
							t.speaker !== undefined
								? `Speaker ${t.speaker}`
								: "Unknown"
						awsSpeakerCounts[speaker] =
							(awsSpeakerCounts[speaker] || 0) + 1
					})
					Object.entries(awsSpeakerCounts).forEach(
						([speaker, count]) => {
							report += `  - ${speaker}: ${count} segments\n`
						}
					)

					report += `\nDeepgram Speaker Distribution:\n`
					const deepgramSpeakerCounts = {}
					results.deepgram.transcripts.forEach((t) => {
						const speaker =
							t.speaker !== undefined
								? `Speaker ${t.speaker}`
								: "Unknown"
						deepgramSpeakerCounts[speaker] =
							(deepgramSpeakerCounts[speaker] || 0) + 1
					})
					Object.entries(deepgramSpeakerCounts).forEach(
						([speaker, count]) => {
							report += `  - ${speaker}: ${count} segments\n`
						}
					)

					report +=
						"\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n"
					report += "                    SIMILARITY ANALYSIS\n"
					report +=
						"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n\n"
					report += `Text Similarity: ${(similarity * 100).toFixed(
						1
					)}%\n`
					report += `Speed Advantage: ${
						awsDuration > deepgramDuration ? "Deepgram" : "AWS"
					} (${Math.abs(awsDuration - deepgramDuration).toFixed(
						2
					)}s faster)\n\n`

					report +=
						"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n"
					report += "                    AWS TRANSCRIPTION\n"
					report +=
						"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n\n"
					results.aws.transcripts.forEach((t, i) => {
						const speaker =
							t.speaker !== undefined
								? `[Speaker ${t.speaker}] `
								: ""
						report += `${speaker}${t.text}\n`
					})

					report +=
						"\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n"
					report += "                  DEEPGRAM TRANSCRIPTION\n"
					report +=
						"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n\n"
					results.deepgram.transcripts.forEach((t, i) => {
						const speaker =
							t.speaker !== undefined
								? `[Speaker ${t.speaker}] `
								: ""
						report += `${speaker}${t.text}\n`
					})

					report +=
						"\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n"
					report += "                      END OF REPORT\n"
					report +=
						"‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n"

					// Download report
					const blob = new Blob([report], { type: "text/plain" })
					const url = URL.createObjectURL(blob)
					const a = document.createElement("a")
					a.href = url
					a.download = `comparison_${
						new Date()
							.toISOString()
							.replace(/:/g, "-")
							.split(".")[0]
					}.txt`
					document.body.appendChild(a)
					a.click()
					document.body.removeChild(a)
					URL.revokeObjectURL(url)

					this.log("üì• Comparison report downloaded", "success")

					// Also generate JSON report
					const jsonReport = {
						metadata: {
							date: new Date().toISOString(),
							filename: this.selectedFile.name,
							test: "AWS Transcribe Call Center vs Deepgram Nova-3",
						},
						metrics: {
							aws: {
								processingTime: awsDuration,
								totalWords: awsWords,
								avgConfidence: awsAvgConfidence,
								speakersDetected: awsSpeakers,
								segments: results.aws.transcripts.length,
							},
							deepgram: {
								processingTime: deepgramDuration,
								totalWords: deepgramWords,
								avgConfidence: deepgramAvgConfidence,
								speakersDetected: deepgramSpeakers,
								segments: results.deepgram.transcripts.length,
							},
						},
						diarization: {
							aws: awsSpeakerCounts,
							deepgram: deepgramSpeakerCounts,
						},
						similarity: similarity,
						transcripts: {
							aws: results.aws.transcripts,
							deepgram: results.deepgram.transcripts,
						},
					}

					const jsonBlob = new Blob(
						[JSON.stringify(jsonReport, null, 2)],
						{ type: "application/json" }
					)
					const jsonUrl = URL.createObjectURL(jsonBlob)
					const jsonA = document.createElement("a")
					jsonA.href = jsonUrl
					jsonA.download = `comparison_${
						new Date()
							.toISOString()
							.replace(/:/g, "-")
							.split(".")[0]
					}.json`
					document.body.appendChild(jsonA)
					jsonA.click()
					document.body.removeChild(jsonA)
					URL.revokeObjectURL(jsonUrl)

					this.log("üì• Comparison JSON downloaded", "success")
				}

				calculateSimilarity(str1, str2) {
					// Simple character-based similarity using Levenshtein distance
					const longer = str1.length > str2.length ? str1 : str2
					const shorter = str1.length > str2.length ? str2 : str1

					if (longer.length === 0) return 1.0

					const editDistance = this.levenshteinDistance(
						longer,
						shorter
					)
					return (longer.length - editDistance) / longer.length
				}

				levenshteinDistance(str1, str2) {
					const matrix = []

					for (let i = 0; i <= str2.length; i++) {
						matrix[i] = [i]
					}

					for (let j = 0; j <= str1.length; j++) {
						matrix[0][j] = j
					}

					for (let i = 1; i <= str2.length; i++) {
						for (let j = 1; j <= str1.length; j++) {
							if (str2.charAt(i - 1) === str1.charAt(j - 1)) {
								matrix[i][j] = matrix[i - 1][j - 1]
							} else {
								matrix[i][j] = Math.min(
									matrix[i - 1][j - 1] + 1,
									matrix[i][j - 1] + 1,
									matrix[i - 1][j] + 1
								)
							}
						}
					}

					return matrix[str2.length][str1.length]
				}

				showNotification(message, type = "info") {
					// Create notification element
					const notification = document.createElement("div")
					notification.style.cssText = `
                    position: fixed;
                    top: 20px;
                    right: 20px;
                    background: ${
						type === "warning"
							? "#ff9800"
							: type === "success"
							? "#4caf50"
							: "#2196f3"
					};
                    color: white;
                    padding: 15px 20px;
                    border-radius: 8px;
                    box-shadow: 0 4px 12px rgba(0,0,0,0.2);
                    z-index: 10000;
                    max-width: 400px;
                    animation: slideIn 0.3s ease-out;
                `
					notification.textContent = message

					// Add to page
					document.body.appendChild(notification)

					// Remove after 5 seconds
					setTimeout(() => {
						notification.style.animation = "slideOut 0.3s ease-in"
						setTimeout(() => {
							if (notification.parentNode) {
								notification.parentNode.removeChild(
									notification
								)
							}
						}, 300)
					}, 5000)
				}

				log(message, type = "info") {
					const entry = document.createElement("div")
					entry.className = `log-entry ${type}`
					entry.textContent = `[${new Date().toLocaleTimeString()}] ${message}`
					this.logEntries.appendChild(entry)
					this.logEntries.scrollTop = this.logEntries.scrollHeight

					// Also log to console
					console.log(`[${type.toUpperCase()}] ${message}`)

					// Keep only last 100 entries
					while (this.logEntries.children.length > 100) {
						this.logEntries.removeChild(this.logEntries.firstChild)
					}
				}
			}

			// Initialize when page loads
			document.addEventListener("DOMContentLoaded", () => {
				if (
					!navigator.mediaDevices ||
					!navigator.mediaDevices.getUserMedia
				) {
					alert(
						"Your browser does not support microphone access. Please use a modern browser."
					)
					return
				}

				new RealtimeTranscription()
			})
		</script>
	</body>
</html>
